########## Vectors ##########

vector
[1,2,3]
[1,2,3]

vector | ndims
[1,2,3]
3

[1,2,3,4] | l2_norm
null
5.477225575051661

[1,2,3,4] | l2_distance([1,3,5,40])
null
36.069377593742864

[1,2,3,4] | dot_product([1,3,5,40])
null
182

[1,2,3,4] | cosine_distance([1,3,5,40])
null
0.1782269734059697

[1,2,3,4] | cosine_similarity([1,3,5,40])
null
0.8217730265940303

########## Env Vars ##########


# llm_getconfig

llm_getconfig | .env.JQLLM_TESTVAR1
null
"value1"


########## Model Creation ##########
# Arguments passed to llm_model are passed to user-facing functions
# like generate, embed etc.
#

# llm_model
llm_model("stories15M.bin").path == env.PWD + "/tests/models/stories15M.bin"
null
true

llm_model("stories15M.bin").name == "stories15M"
null
true

# Params: note that steps is set by the user and the rest are defaults
llm_model("stories15M.bin"; {"steps": 200}).params
null
{ "temperature": 1, "topp": 0.9, "steps": 200, "rng_seed": 0}

########## LLAMA2C ##########

[.[] | llm_tokenize("tokenizer.bin"; 32000)]
["I believe the meaning of life is"]
[[1,306,4658,278,6593,310,2834,338]]

[.[] | llm_tokenize("tokenizer.bin"; 32000)]
["Simply put, the theory of relativity states that "]
[[1,3439,17632,1925,29892,278,6368,310,14215,537,5922,393, 29871]]

[.[] | llm_embed("tokenizer.bin"; 32000)]
["Simply put, the theory of relativity states that "]
[[1,3439,17632,1925,29892,278,6368,310,14215,537,5922,393, 29871]]

# llm_generate

# For lack of a better approach just check that it indeed generates a string starting with the prompt
[.[] | llm_generate | startswith("hello world")]
["hello world"]
[true]


